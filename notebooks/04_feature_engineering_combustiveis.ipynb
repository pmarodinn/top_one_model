{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cab9a1b",
   "metadata": {},
   "source": [
    "# Feature Engineering - Dados de Combust√≠veis por Regi√£o\n",
    "\n",
    "**Projeto:** Top One Model - Sistema de Modelagem de Risco de Cr√©dito\n",
    "\n",
    "**Objetivo:**\n",
    "- Processar e organizar os dados brutos de combust√≠veis da ANP\n",
    "- Criar estrutura de dados padronizada e consistente\n",
    "- Separar informa√ß√µes por tempo, regi√£o, cidade e valores\n",
    "- Preparar dados para implementa√ß√£o futura do modelo de risco\n",
    "\n",
    "**Dados de Entrada:**\n",
    "```\n",
    "data/external_data/macro_specified_data/fuel_prices/raw_data/\n",
    "‚îú‚îÄ‚îÄ resumo/     # Dados consolidados por regi√£o\n",
    "‚îî‚îÄ‚îÄ revendas/   # Dados detalhados por posto\n",
    "```\n",
    "\n",
    "**Dados de Sa√≠da:**\n",
    "```\n",
    "data/external_data/macro_specified_data/fuel_prices/processed_data/\n",
    "‚îú‚îÄ‚îÄ resumo_consolidado.parquet\n",
    "‚îú‚îÄ‚îÄ revendas_consolidado.parquet\n",
    "‚îî‚îÄ‚îÄ indices_regionais.parquet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe0299",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o Inicial e Importa√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ae80cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FEATURE ENGINEERING - DADOS DE COMBUST√çVEIS\n",
      "============================================================\n",
      "üìÖ Data de execu√ß√£o: 04/08/2025 18:05:58\n",
      "üéØ Objetivo: Processar e organizar dados para o modelo\n",
      "‚úÖ Bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Importa√ß√µes essenciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Para processamento paralelo e otimiza√ß√£o\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import glob\n",
    "\n",
    "print(\"üîß FEATURE ENGINEERING - DADOS DE COMBUST√çVEIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üìÖ Data de execu√ß√£o:\", datetime.now().strftime('%d/%m/%Y %H:%M:%S'))\n",
    "print(\"üéØ Objetivo: Processar e organizar dados para o modelo\")\n",
    "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1dec4",
   "metadata": {},
   "source": [
    "## 2. Configura√ß√£o de Caminhos e Estrutura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b35eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ ESTRUTURA DE DADOS CONFIGURADA:\n",
      "   üìÇ Raw Data Resumo: /home/usuario/Documentos/top_one_model_01/data/external_data/macro_specified_data/fuel_prices/raw_data/resumo\n",
      "   üìÇ Raw Data Revendas: /home/usuario/Documentos/top_one_model_01/data/external_data/macro_specified_data/fuel_prices/raw_data/revendas\n",
      "   üìÇ Processed Data: /home/usuario/Documentos/top_one_model_01/data/external_data/macro_specified_data/fuel_prices/processed_data\n",
      "\n",
      "üìä DADOS DISPON√çVEIS:\n",
      "   ‚Ä¢ Resumos: 140 arquivos\n",
      "   ‚Ä¢ Revendas: 139 arquivos\n",
      "‚úÖ Estrutura verificada com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o das pastas\n",
    "project_root = Path('/home/usuario/Documentos/top_one_model_01')\n",
    "fuel_prices_root = project_root / 'data' / 'external_data' / 'macro_specified_data' / 'fuel_prices'\n",
    "\n",
    "# Pastas de dados\n",
    "raw_data_path = fuel_prices_root / 'raw_data'\n",
    "processed_data_path = fuel_prices_root / 'processed_data'\n",
    "\n",
    "# Subpastas de raw data\n",
    "pasta_resumo = raw_data_path / 'resumo'\n",
    "pasta_revendas = raw_data_path / 'revendas'\n",
    "\n",
    "# Criar pasta de dados processados se n√£o existir\n",
    "processed_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üìÅ ESTRUTURA DE DADOS CONFIGURADA:\")\n",
    "print(f\"   üìÇ Raw Data Resumo: {pasta_resumo}\")\n",
    "print(f\"   üìÇ Raw Data Revendas: {pasta_revendas}\")\n",
    "print(f\"   üìÇ Processed Data: {processed_data_path}\")\n",
    "\n",
    "# Verificar dados dispon√≠veis\n",
    "arquivos_resumo = list(pasta_resumo.glob('*.xlsx'))\n",
    "arquivos_revendas = list(pasta_revendas.glob('*.xlsx'))\n",
    "\n",
    "print(f\"\\nüìä DADOS DISPON√çVEIS:\")\n",
    "print(f\"   ‚Ä¢ Resumos: {len(arquivos_resumo)} arquivos\")\n",
    "print(f\"   ‚Ä¢ Revendas: {len(arquivos_revendas)} arquivos\")\n",
    "print(\"‚úÖ Estrutura verificada com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff56ee",
   "metadata": {},
   "source": [
    "## 3. An√°lise Inicial da Estrutura dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b972b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç AN√ÅLISE ESTRUTURAL DOS DADOS\n",
      "==================================================\n",
      "\n",
      "üìã AN√ÅLISE DOS RESUMOS (primeiros 3 arquivos):\n",
      "\n",
      "üìÑ 1. resumo_2022-08-21_2022-08-27.xlsx\n",
      "   ‚ùå Erro: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "\n",
      "üìÑ 2. resumo_2022-08-28_2022-09-03.xlsx\n",
      "   ‚ùå Erro: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "\n",
      "üìÑ 3. resumo_2022-09-04_2022-09-10.xlsx\n",
      "   üìä Shape: 181 linhas x 12 colunas\n",
      "   üó∫Ô∏è Colunas geogr√°ficas: 0 encontradas\n",
      "   üí∞ Colunas de pre√ßo: 0 encontradas\n",
      "   ‚õΩ Colunas de combust√≠vel: 0 encontradas\n",
      "\n",
      "üè™ AN√ÅLISE DAS REVENDAS (primeiros 3 arquivos):\n",
      "\n",
      "üìÑ 1. revendas_2022-09-04_2022-09-10.xlsx\n",
      "   ‚ùå Erro: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "\n",
      "üìÑ 2. revendas_2022-09-11_2022-09-17.xlsx\n",
      "   ‚ùå Erro: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "\n",
      "üìÑ 3. revendas_2022-09-25_2022-10-01.xlsx\n",
      "   ‚ùå Erro: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "\n",
      "‚úÖ AN√ÅLISE ESTRUTURAL CONCLU√çDA!\n"
     ]
    }
   ],
   "source": [
    "def analisar_estrutura_arquivo(arquivo_path):\n",
    "    \"\"\"\n",
    "    Analisa a estrutura de um arquivo Excel de combust√≠veis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ler arquivo\n",
    "        df = pd.read_excel(arquivo_path, engine='openpyxl')\n",
    "        \n",
    "        # Extrair informa√ß√µes b√°sicas\n",
    "        info = {\n",
    "            'arquivo': arquivo_path.name,\n",
    "            'shape': df.shape,\n",
    "            'colunas': list(df.columns),\n",
    "            'colunas_count': len(df.columns),\n",
    "            'tipos_dados': df.dtypes.to_dict(),\n",
    "            'primeiras_linhas': df.head(3).to_dict('records'),\n",
    "            'valores_nulos': df.isnull().sum().to_dict(),\n",
    "            'erro': None\n",
    "        }\n",
    "        \n",
    "        # Identificar colunas importantes\n",
    "        colunas_geo = [col for col in df.columns if any(termo in str(col).lower() for termo in ['estado', 'uf', 'munic√≠pio', 'regiao', 'cidade'])]\n",
    "        colunas_preco = [col for col in df.columns if any(termo in str(col).lower() for termo in ['pre√ßo', 'preco', 'valor', 'media'])]\n",
    "        colunas_combustivel = [col for col in df.columns if any(termo in str(col).lower() for termo in ['gasolina', 'etanol', 'diesel', 'gnv'])]\n",
    "        \n",
    "        info['colunas_geograficas'] = colunas_geo\n",
    "        info['colunas_preco'] = colunas_preco\n",
    "        info['colunas_combustivel'] = colunas_combustivel\n",
    "        \n",
    "        return info\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'arquivo': arquivo_path.name,\n",
    "            'erro': str(e)\n",
    "        }\n",
    "\n",
    "# Analisar alguns arquivos de cada tipo\n",
    "print(\"üîç AN√ÅLISE ESTRUTURAL DOS DADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nüìã AN√ÅLISE DOS RESUMOS (primeiros 3 arquivos):\")\n",
    "for i, arquivo in enumerate(sorted(arquivos_resumo)[:3]):\n",
    "    info = analisar_estrutura_arquivo(arquivo)\n",
    "    print(f\"\\nüìÑ {i+1}. {info['arquivo']}\")\n",
    "    \n",
    "    if info.get('erro'):\n",
    "        print(f\"   ‚ùå Erro: {info['erro']}\")\n",
    "    else:\n",
    "        print(f\"   üìä Shape: {info['shape'][0]:,} linhas x {info['shape'][1]} colunas\")\n",
    "        print(f\"   üó∫Ô∏è Colunas geogr√°ficas: {len(info['colunas_geograficas'])} encontradas\")\n",
    "        print(f\"   üí∞ Colunas de pre√ßo: {len(info['colunas_preco'])} encontradas\")\n",
    "        print(f\"   ‚õΩ Colunas de combust√≠vel: {len(info['colunas_combustivel'])} encontradas\")\n",
    "\n",
    "print(\"\\nüè™ AN√ÅLISE DAS REVENDAS (primeiros 3 arquivos):\")\n",
    "for i, arquivo in enumerate(sorted(arquivos_revendas)[:3]):\n",
    "    info = analisar_estrutura_arquivo(arquivo)\n",
    "    print(f\"\\nüìÑ {i+1}. {info['arquivo']}\")\n",
    "    \n",
    "    if info.get('erro'):\n",
    "        print(f\"   ‚ùå Erro: {info['erro']}\")\n",
    "    else:\n",
    "        print(f\"   üìä Shape: {info['shape'][0]:,} linhas x {info['shape'][1]} colunas\")\n",
    "        print(f\"   üó∫Ô∏è Colunas geogr√°ficas: {len(info['colunas_geograficas'])} encontradas\")\n",
    "        print(f\"   üí∞ Colunas de pre√ßo: {len(info['colunas_preco'])} encontradas\")\n",
    "        print(f\"   ‚õΩ Colunas de combust√≠vel: {len(info['colunas_combustivel'])} encontradas\")\n",
    "\n",
    "print(\"\\n‚úÖ AN√ÅLISE ESTRUTURAL CONCLU√çDA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9368ef",
   "metadata": {},
   "source": [
    "## 4. Fun√ß√µes de Limpeza e Padroniza√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ef0d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fun√ß√µes de limpeza e padroniza√ß√£o criadas!\n"
     ]
    }
   ],
   "source": [
    "def extrair_periodo_do_nome(nome_arquivo):\n",
    "    \"\"\"\n",
    "    Extrai o per√≠odo (data inicial e final) do nome do arquivo\n",
    "    \"\"\"\n",
    "    # Padr√£o: tipo_YYYY-MM-DD_YYYY-MM-DD.xlsx\n",
    "    match = re.search(r'(\\d{4}-\\d{2}-\\d{2})_(\\d{4}-\\d{2}-\\d{2})', nome_arquivo)\n",
    "    \n",
    "    if match:\n",
    "        data_inicio = pd.to_datetime(match.group(1))\n",
    "        data_fim = pd.to_datetime(match.group(2))\n",
    "        \n",
    "        return {\n",
    "            'data_inicio': data_inicio,\n",
    "            'data_fim': data_fim,\n",
    "            'ano': data_inicio.year,\n",
    "            'mes': data_inicio.month,\n",
    "            'semana_ano': data_inicio.isocalendar()[1],\n",
    "            'periodo_string': f\"{data_inicio.strftime('%Y-%m-%d')} a {data_fim.strftime('%Y-%m-%d')}\"\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "def limpar_nomes_colunas(df):\n",
    "    \"\"\"\n",
    "    Limpa e padroniza nomes das colunas\n",
    "    \"\"\"\n",
    "    # Remover espa√ßos extras e caracteres especiais\n",
    "    colunas_limpas = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Converter para string e limpar\n",
    "        col_limpa = str(col).strip()\n",
    "        \n",
    "        # Remover quebras de linha e espa√ßos m√∫ltiplos\n",
    "        col_limpa = re.sub(r'\\s+', ' ', col_limpa)\n",
    "        \n",
    "        # Remover caracteres especiais no in√≠cio/fim\n",
    "        col_limpa = re.sub(r'^[^a-zA-Z0-9]+|[^a-zA-Z0-9]+$', '', col_limpa)\n",
    "        \n",
    "        colunas_limpas.append(col_limpa)\n",
    "    \n",
    "    df.columns = colunas_limpas\n",
    "    return df\n",
    "\n",
    "def identificar_tipo_combustivel(nome_coluna):\n",
    "    \"\"\"\n",
    "    Identifica o tipo de combust√≠vel baseado no nome da coluna\n",
    "    \"\"\"\n",
    "    nome_lower = str(nome_coluna).lower()\n",
    "    \n",
    "    if 'gasolina' in nome_lower or 'gasolin' in nome_lower:\n",
    "        return 'gasolina'\n",
    "    elif 'etanol' in nome_lower or 'alcool' in nome_lower or '√°lcool' in nome_lower:\n",
    "        return 'etanol'\n",
    "    elif 'diesel' in nome_lower:\n",
    "        return 'diesel'\n",
    "    elif 'gnv' in nome_lower or 'g√°s natural' in nome_lower:\n",
    "        return 'gnv'\n",
    "    else:\n",
    "        return 'outro'\n",
    "\n",
    "def limpar_valores_numericos(series):\n",
    "    \"\"\"\n",
    "    Limpa e converte valores num√©ricos (pre√ßos)\n",
    "    \"\"\"\n",
    "    # Converter para string primeiro\n",
    "    series_str = series.astype(str)\n",
    "    \n",
    "    # Remover s√≠mbolos de moeda e espa√ßos\n",
    "    series_clean = series_str.str.replace(r'[R$\\s]', '', regex=True)\n",
    "    \n",
    "    # Trocar v√≠rgula por ponto para decimal\n",
    "    series_clean = series_clean.str.replace(',', '.')\n",
    "    \n",
    "    # Converter para num√©rico\n",
    "    return pd.to_numeric(series_clean, errors='coerce')\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de limpeza e padroniza√ß√£o criadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a2b5f",
   "metadata": {},
   "source": [
    "## 5. Processamento dos Dados de Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5951c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ PROCESSANDO TODOS OS DADOS DE RESUMO (2022-2025)\n",
      "============================================================\n",
      "üí° Processando todos os arquivos dispon√≠veis desde a primeira coleta...\n",
      "üìã Total de arquivos para processar: 140\n",
      "üìÖ Per√≠odo estimado: resumo_2022-08-21_2022-08-27.xlsx at√© resumo_2025-07-27_2025-08-02.xlsx\n",
      "üìÑ [1/140] Processando: resumo_2022-08-21_2022-08-27.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2022-08-21_2022-08-27.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [2/140] Processando: resumo_2022-08-28_2022-09-03.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2022-08-28_2022-09-03.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [3/140] Processando: resumo_2022-09-04_2022-09-10.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [4/140] Processando: resumo_2022-09-11_2022-09-17.xlsx\n",
      "   ‚úÖ Sucesso: 147 registros\n",
      "üìÑ [5/140] Processando: resumo_2022-09-18_2022-09-24.xlsx\n",
      "   ‚úÖ Sucesso: 13 registros\n",
      "üìÑ [6/140] Processando: resumo_2022-09-25_2022-10-01.xlsx\n",
      "   ‚úÖ Sucesso: 174 registros\n",
      "üìÑ [7/140] Processando: resumo_2022-10-30_2022-11-05.xlsx\n",
      "   ‚úÖ Sucesso: 161 registros\n",
      "üìÑ [8/140] Processando: resumo_2022-11-06_2022-11-12.xlsx\n",
      "   ‚úÖ Sucesso: 174 registros\n",
      "üìÑ [9/140] Processando: resumo_2022-11-20_2022-11-26.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [10/140] Processando: resumo_2022-12-04_2022-12-10.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2022-12-04_2022-12-10.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [11/140] Processando: resumo_2022-12-11_2022-12-17.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2022-12-11_2022-12-17.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [12/140] Processando: resumo_2022-12-18_2022-12-24.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2022-12-18_2022-12-24.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [13/140] Processando: resumo_2023-01-01_2023-01-07.xlsx\n",
      "   ‚úÖ Sucesso: 162 registros\n",
      "üìÑ [14/140] Processando: resumo_2023-01-08_2023-01-14.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [15/140] Processando: resumo_2023-01-15_2023-01-21.xlsx\n",
      "   ‚úÖ Sucesso: 175 registros\n",
      "üìÑ [16/140] Processando: resumo_2023-01-22_2023-01-28.xlsx\n",
      "   ‚úÖ Sucesso: 175 registros\n",
      "üìÑ [17/140] Processando: resumo_2023-01-29_2023-02-04.xlsx\n",
      "   ‚úÖ Sucesso: 168 registros\n",
      "üìÑ [18/140] Processando: resumo_2023-02-05_2023-02-11.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [19/140] Processando: resumo_2023-02-12_2023-02-18.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [20/140] Processando: resumo_2023-02-19_2023-02-25.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "\n",
      "   üìä Progresso: 20/140 (75.0% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 2,375\n",
      "üìÑ [21/140] Processando: resumo_2023-02-26_2023-03-04.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2023-02-26_2023-03-04.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [22/140] Processando: resumo_2023-03-05_2023-03-11.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2023-03-05_2023-03-11.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [23/140] Processando: resumo_2023-03-12_2023-03-18.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2023-03-12_2023-03-18.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [24/140] Processando: resumo_2023-03-19_2023-03-25.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2023-03-19_2023-03-25.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [25/140] Processando: resumo_2023-03-26_2023-04-01.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2023-03-26_2023-04-01.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [26/140] Processando: resumo_2023-04-09_2023-04-15.xlsx\n",
      "   ‚ùå Erro ao processar resumo_2023-04-09_2023-04-15.xlsx: ExternalReference.__init__() missing 1 required positional argument: 'id'\n",
      "   ‚ùå Falha no processamento\n",
      "üìÑ [27/140] Processando: resumo_2023-05-07_2023-05-13.xlsx\n",
      "   ‚úÖ Sucesso: 174 registros\n",
      "üìÑ [28/140] Processando: resumo_2023-05-14_2023-05-20.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [29/140] Processando: resumo_2023-05-21_2023-05-27.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [30/140] Processando: resumo_2023-05-28_2023-06-03.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [31/140] Processando: resumo_2023-06-04_2023-06-10.xlsx\n",
      "   ‚úÖ Sucesso: 175 registros\n",
      "üìÑ [32/140] Processando: resumo_2023-06-11_2023-06-17.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [33/140] Processando: resumo_2023-06-18_2023-06-24.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [34/140] Processando: resumo_2023-06-25_2023-07-01.xlsx\n",
      "   ‚úÖ Sucesso: 174 registros\n",
      "üìÑ [35/140] Processando: resumo_2023-07-02_2023-07-08.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [36/140] Processando: resumo_2023-07-09_2023-07-15.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [37/140] Processando: resumo_2023-07-16_2023-07-22.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [38/140] Processando: resumo_2023-07-23_2023-07-29.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [39/140] Processando: resumo_2023-07-30_2023-08-05.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [40/140] Processando: resumo_2023-08-06_2023-08-12.xlsx\n",
      "   ‚úÖ Sucesso: 169 registros\n",
      "\n",
      "   üìä Progresso: 40/140 (72.5% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 4,783\n",
      "üìÑ [41/140] Processando: resumo_2023-08-13_2023-08-19.xlsx\n",
      "   ‚úÖ Sucesso: 175 registros\n",
      "üìÑ [42/140] Processando: resumo_2023-08-20_2023-08-26.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [43/140] Processando: resumo_2023-08-27_2023-09-02.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [44/140] Processando: resumo_2023-09-03_2023-09-09.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [45/140] Processando: resumo_2023-09-10_2023-09-16.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [46/140] Processando: resumo_2023-09-17_2023-09-23.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [47/140] Processando: resumo_2023-09-24_2023-09-30.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [48/140] Processando: resumo_2023-10-01_2023-10-07.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [49/140] Processando: resumo_2023-10-08_2023-10-14.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [50/140] Processando: resumo_2023-10-15_2023-10-21.xlsx\n",
      "   ‚úÖ Sucesso: 163 registros\n",
      "üìÑ [51/140] Processando: resumo_2023-10-22_2023-10-28.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [52/140] Processando: resumo_2023-10-29_2023-11-04.xlsx\n",
      "   ‚úÖ Sucesso: 174 registros\n",
      "üìÑ [53/140] Processando: resumo_2023-11-05_2023-11-11.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [54/140] Processando: resumo_2023-11-12_2023-11-18.xlsx\n",
      "   ‚úÖ Sucesso: 169 registros\n",
      "üìÑ [55/140] Processando: resumo_2023-11-19_2023-11-25.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [56/140] Processando: resumo_2023-11-26_2023-12-02.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [57/140] Processando: resumo_2023-12-03_2023-12-09.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [58/140] Processando: resumo_2023-12-10_2023-12-16.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [59/140] Processando: resumo_2023-12-17_2023-12-23.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [60/140] Processando: resumo_2023-12-24_2023-12-30.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "\n",
      "   üìä Progresso: 60/140 (81.7% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 8,181\n",
      "üìÑ [61/140] Processando: resumo_2024-01-07_2024-01-13.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [62/140] Processando: resumo_2024-01-14_2024-01-20.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [63/140] Processando: resumo_2024-01-21_2024-01-27.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [64/140] Processando: resumo_2024-01-28_2024-02-03.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [65/140] Processando: resumo_2024-02-04_2024-02-10.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [66/140] Processando: resumo_2024-02-11_2024-02-17.xlsx\n",
      "   ‚úÖ Sucesso: 168 registros\n",
      "üìÑ [67/140] Processando: resumo_2024-02-18_2024-02-24.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [68/140] Processando: resumo_2024-02-25_2024-03-02.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [69/140] Processando: resumo_2024-03-03_2024-03-09.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [70/140] Processando: resumo_2024-03-10_2024-03-16.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [71/140] Processando: resumo_2024-03-17_2024-03-23.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [72/140] Processando: resumo_2024-03-24_2024-03-30.xlsx\n",
      "   ‚úÖ Sucesso: 168 registros\n",
      "üìÑ [73/140] Processando: resumo_2024-03-31_2024-04-06.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [74/140] Processando: resumo_2024-04-07_2024-04-13.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [75/140] Processando: resumo_2024-04-21_2024-04-27.xlsx\n",
      "   ‚úÖ Sucesso: 168 registros\n",
      "üìÑ [76/140] Processando: resumo_2024-04-28_2024-05-04.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [77/140] Processando: resumo_2024-05-05_2024-05-11.xlsx\n",
      "   ‚úÖ Sucesso: 164 registros\n",
      "üìÑ [78/140] Processando: resumo_2024-05-12_2024-05-18.xlsx\n",
      "   ‚úÖ Sucesso: 163 registros\n",
      "üìÑ [79/140] Processando: resumo_2024-05-19_2024-05-25.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [80/140] Processando: resumo_2024-05-26_2024-06-01.xlsx\n",
      "   ‚úÖ Sucesso: 163 registros\n",
      "\n",
      "   üìä Progresso: 80/140 (86.2% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 11,532\n",
      "üìÑ [81/140] Processando: resumo_2024-06-02_2024-06-08.xlsx\n",
      "   ‚úÖ Sucesso: 169 registros\n",
      "üìÑ [82/140] Processando: resumo_2024-06-09_2024-06-15.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [83/140] Processando: resumo_2024-06-16_2024-06-22.xlsx\n",
      "   ‚úÖ Sucesso: 163 registros\n",
      "üìÑ [84/140] Processando: resumo_2024-06-23_2024-06-29.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [85/140] Processando: resumo_2024-06-30_2024-07-06.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [86/140] Processando: resumo_2024-07-07_2024-07-13.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [87/140] Processando: resumo_2024-07-14_2024-07-20.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [88/140] Processando: resumo_2024-07-21_2024-07-27.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [89/140] Processando: resumo_2024-07-28_2024-08-03.xlsx\n",
      "   ‚úÖ Sucesso: 160 registros\n",
      "üìÑ [90/140] Processando: resumo_2024-08-04_2024-08-10.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [91/140] Processando: resumo_2024-08-11_2024-08-17.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [92/140] Processando: resumo_2024-08-18_2024-08-24.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [93/140] Processando: resumo_2024-08-25_2024-08-31.xlsx\n",
      "   ‚úÖ Sucesso: 164 registros\n",
      "üìÑ [94/140] Processando: resumo_2024-09-01_2024-09-07.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [95/140] Processando: resumo_2024-09-08_2024-09-14.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [96/140] Processando: resumo_2024-09-15_2024-09-21.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [97/140] Processando: resumo_2024-09-22_2024-09-28.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [98/140] Processando: resumo_2024-09-29_2024-10-05.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [99/140] Processando: resumo_2024-10-06_2024-10-12.xlsx\n",
      "   ‚úÖ Sucesso: 169 registros\n",
      "üìÑ [100/140] Processando: resumo_2024-10-13_2024-10-19.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "\n",
      "   üìä Progresso: 100/140 (89.0% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 14,898\n",
      "üìÑ [101/140] Processando: resumo_2024-10-20_2024-10-26.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [102/140] Processando: resumo_2024-10-27_2024-11-02.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [103/140] Processando: resumo_2024-11-03_2024-11-09.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [104/140] Processando: resumo_2024-11-10_2024-11-16.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [105/140] Processando: resumo_2024-11-17_2024-11-23.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [106/140] Processando: resumo_2024-11-24_2024-11-30.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [107/140] Processando: resumo_2024-12-01_2024-12-07.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [108/140] Processando: resumo_2024-12-08_2024-12-14.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [109/140] Processando: resumo_2024-12-15_2024-12-21.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [110/140] Processando: resumo_2024-12-29_2025-01-04.xlsx\n",
      "   ‚úÖ Sucesso: 162 registros\n",
      "üìÑ [111/140] Processando: resumo_2025-01-05_2025-01-11.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [112/140] Processando: resumo_2025-01-12_2025-01-18.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [113/140] Processando: resumo_2025-01-19_2025-01-25.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [114/140] Processando: resumo_2025-01-26_2025-02-01.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [115/140] Processando: resumo_2025-02-02_2025-02-08.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [116/140] Processando: resumo_2025-02-09_2025-02-15.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [117/140] Processando: resumo_2025-02-16_2025-02-22.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [118/140] Processando: resumo_2025-02-23_2025-03-01.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [119/140] Processando: resumo_2025-03-02_2025-03-08.xlsx\n",
      "   ‚úÖ Sucesso: 169 registros\n",
      "üìÑ [120/140] Processando: resumo_2025-03-09_2025-03-15.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "\n",
      "   üìä Progresso: 120/140 (90.8% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 18,288\n",
      "üìÑ [121/140] Processando: resumo_2025-03-16_2025-03-22.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [122/140] Processando: resumo_2025-03-23_2025-03-29.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [123/140] Processando: resumo_2025-03-30_2025-04-05.xlsx\n",
      "   ‚úÖ Sucesso: 152 registros\n",
      "üìÑ [124/140] Processando: resumo_2025-04-06_2025-04-12.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "üìÑ [125/140] Processando: resumo_2025-04-13_2025-04-19.xlsx\n",
      "   ‚úÖ Sucesso: 169 registros\n",
      "üìÑ [126/140] Processando: resumo_2025-04-20_2025-04-26.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [127/140] Processando: resumo_2025-04-27_2025-05-03.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [128/140] Processando: resumo_2025-05-04_2025-05-10.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [129/140] Processando: resumo_2025-05-11_2025-05-17.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [130/140] Processando: resumo_2025-05-18_2025-05-24.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [131/140] Processando: resumo_2025-05-25_2025-05-31.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [132/140] Processando: resumo_2025-06-01_2025-06-07.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [133/140] Processando: resumo_2025-06-08_2025-06-14.xlsx\n",
      "   ‚úÖ Sucesso: 172 registros\n",
      "üìÑ [134/140] Processando: resumo_2025-06-15_2025-06-21.xlsx\n",
      "   ‚úÖ Sucesso: 171 registros\n",
      "üìÑ [135/140] Processando: resumo_2025-06-22_2025-06-28.xlsx\n",
      "   ‚úÖ Sucesso: 170 registros\n",
      "üìÑ [136/140] Processando: resumo_2025-06-29_2025-07-05.xlsx\n",
      "   ‚úÖ Sucesso: 173 registros\n",
      "üìÑ [137/140] Processando: resumo_2025-07-06_2025-07-12.xlsx\n",
      "   ‚úÖ Sucesso: 167 registros\n",
      "üìÑ [138/140] Processando: resumo_2025-07-13_2025-07-19.xlsx\n",
      "   ‚úÖ Sucesso: 168 registros\n",
      "üìÑ [139/140] Processando: resumo_2025-07-20_2025-07-26.xlsx\n",
      "   ‚úÖ Sucesso: 165 registros\n",
      "üìÑ [140/140] Processando: resumo_2025-07-27_2025-08-02.xlsx\n",
      "   ‚úÖ Sucesso: 166 registros\n",
      "\n",
      "   üìä Progresso: 140/140 (92.1% sucesso at√© agora)\n",
      "   üíæ Registros acumulados: 21,663\n",
      "\n",
      "üìã RELAT√ìRIO FINAL DE PROCESSAMENTO - RESUMOS COMPLETOS:\n",
      "   ‚Ä¢ ‚úÖ Sucessos: 129\n",
      "   ‚Ä¢ ‚ùå Falhas: 11\n",
      "   ‚Ä¢ üìà Taxa de sucesso: 92.1%\n",
      "\n",
      "üîó CONSOLIDANDO TODOS OS DADOS DE RESUMO...\n",
      "   üìä Dataset consolidado: 21,663 registros\n",
      "   üìÖ Per√≠odo completo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "   üìà Anos cobertos: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "   üó∫Ô∏è Estados √∫nicos: 27\n",
      "   üèôÔ∏è Munic√≠pios √∫nicos: 27\n",
      "   üíæ Dados completos salvos em CSV: /home/usuario/Documentos/top_one_model_01/data/external_data/macro_specified_data/fuel_prices/processed_data/resumo_consolidado_completo.csv\n",
      "   ‚ö†Ô∏è Erro com parquet: (\"Expected bytes, got a 'datetime.datetime' object\", 'Conversion failed for column AG√äNCIA NACIONAL DO PETR√ìLEO, G√ÅS NATURAL E BIOCOMBUST√çVEIS - ANP with type object')\n",
      "\n",
      "‚úÖ PROCESSAMENTO COMPLETO DE RESUMOS CONCLU√çDO!\n",
      "üéØ Agora temos dados desde 2022 at√© 2025!\n"
     ]
    }
   ],
   "source": [
    "def processar_arquivo_resumo(arquivo_path):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de resumo individual\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ler arquivo\n",
    "        df = pd.read_excel(arquivo_path, engine='openpyxl')\n",
    "        \n",
    "        # Extrair per√≠odo do nome do arquivo\n",
    "        periodo_info = extrair_periodo_do_nome(arquivo_path.name)\n",
    "        \n",
    "        if not periodo_info:\n",
    "            return None\n",
    "        \n",
    "        # Limpar nomes das colunas\n",
    "        df = limpar_nomes_colunas(df)\n",
    "        \n",
    "        # Pular linhas de cabe√ßalho da ANP se necess√°rio\n",
    "        # Encontrar a linha onde come√ßam os dados reais\n",
    "        linha_inicio = 0\n",
    "        for i, row in df.iterrows():\n",
    "            # Procurar por indicadores de in√≠cio de dados\n",
    "            if any(str(val).lower() in ['regi√£o', 'estado', 'uf'] for val in row.values if pd.notna(val)):\n",
    "                linha_inicio = i\n",
    "                break\n",
    "        \n",
    "        # Se encontrou linha de cabe√ßalho, reconstruir DataFrame\n",
    "        if linha_inicio > 0:\n",
    "            # Usar a linha encontrada como header\n",
    "            new_header = df.iloc[linha_inicio].fillna('').astype(str)\n",
    "            df = df.iloc[linha_inicio + 1:].copy()\n",
    "            df.columns = new_header\n",
    "            df = limpar_nomes_colunas(df)\n",
    "        \n",
    "        # Remover linhas completamente vazias\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Adicionar informa√ß√µes de per√≠odo\n",
    "        for key, value in periodo_info.items():\n",
    "            df[key] = value\n",
    "        \n",
    "        # Adicionar tipo de dados\n",
    "        df['tipo_dados'] = 'resumo'\n",
    "        df['arquivo_origem'] = arquivo_path.name\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro ao processar {arquivo_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Processar TODOS os arquivos de resumo desde 2022\n",
    "print(\"üîÑ PROCESSANDO TODOS OS DADOS DE RESUMO (2022-2025)\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üí° Processando todos os arquivos dispon√≠veis desde a primeira coleta...\")\n",
    "\n",
    "resumos_processados = []\n",
    "sucessos_resumo = 0\n",
    "falhas_resumo = 0\n",
    "\n",
    "# Processar TODOS os arquivos dispon√≠veis (ordenados cronologicamente)\n",
    "todos_resumos = sorted(arquivos_resumo)\n",
    "\n",
    "print(f\"üìã Total de arquivos para processar: {len(todos_resumos)}\")\n",
    "print(f\"üìÖ Per√≠odo estimado: {todos_resumos[0].name} at√© {todos_resumos[-1].name}\")\n",
    "\n",
    "for i, arquivo in enumerate(todos_resumos, 1):\n",
    "    print(f\"üìÑ [{i}/{len(todos_resumos)}] Processando: {arquivo.name}\")\n",
    "    \n",
    "    df_processado = processar_arquivo_resumo(arquivo)\n",
    "    \n",
    "    if df_processado is not None:\n",
    "        resumos_processados.append(df_processado)\n",
    "        sucessos_resumo += 1\n",
    "        print(f\"   ‚úÖ Sucesso: {len(df_processado):,} registros\")\n",
    "    else:\n",
    "        falhas_resumo += 1\n",
    "        print(f\"   ‚ùå Falha no processamento\")\n",
    "    \n",
    "    # Mostrar progresso a cada 20 arquivos\n",
    "    if i % 20 == 0 or i == len(todos_resumos):\n",
    "        taxa_sucesso = (sucessos_resumo / i) * 100\n",
    "        print(f\"\\n   üìä Progresso: {i}/{len(todos_resumos)} ({taxa_sucesso:.1f}% sucesso at√© agora)\")\n",
    "        print(f\"   üíæ Registros acumulados: {sum(len(df) for df in resumos_processados):,}\")\n",
    "\n",
    "print(f\"\\nüìã RELAT√ìRIO FINAL DE PROCESSAMENTO - RESUMOS COMPLETOS:\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ Sucessos: {sucessos_resumo}\")\n",
    "print(f\"   ‚Ä¢ ‚ùå Falhas: {falhas_resumo}\")\n",
    "print(f\"   ‚Ä¢ üìà Taxa de sucesso: {(sucessos_resumo/(sucessos_resumo+falhas_resumo)*100) if (sucessos_resumo+falhas_resumo) > 0 else 0:.1f}%\")\n",
    "\n",
    "if resumos_processados:\n",
    "    print(f\"\\nüîó CONSOLIDANDO TODOS OS DADOS DE RESUMO...\")\n",
    "    resumo_consolidado = pd.concat(resumos_processados, ignore_index=True)\n",
    "    \n",
    "    print(f\"   üìä Dataset consolidado: {len(resumo_consolidado):,} registros\")\n",
    "    print(f\"   üìÖ Per√≠odo completo: {resumo_consolidado['data_inicio'].min()} a {resumo_consolidado['data_fim'].max()}\")\n",
    "    print(f\"   üìà Anos cobertos: {sorted(resumo_consolidado['ano'].unique())}\")\n",
    "    print(f\"   üó∫Ô∏è Estados √∫nicos: {resumo_consolidado['ESTADO'].nunique() if 'ESTADO' in resumo_consolidado.columns else 'N/A'}\")\n",
    "    print(f\"   üèôÔ∏è Munic√≠pios √∫nicos: {resumo_consolidado['MUNIC√çPIO'].nunique() if 'MUNIC√çPIO' in resumo_consolidado.columns else 'N/A'}\")\n",
    "    \n",
    "    # Salvar dados consolidados completos\n",
    "    try:\n",
    "        arquivo_resumo_consolidado = processed_data_path / 'resumo_consolidado_completo.parquet'\n",
    "        resumo_consolidado.to_parquet(arquivo_resumo_consolidado, index=False)\n",
    "        print(f\"   üíæ Dados completos salvos em: {arquivo_resumo_consolidado}\")\n",
    "    except Exception as e:\n",
    "        # Fallback para CSV se parquet falhar\n",
    "        arquivo_resumo_consolidado = processed_data_path / 'resumo_consolidado_completo.csv'\n",
    "        resumo_consolidado.to_csv(arquivo_resumo_consolidado, index=False)\n",
    "        print(f\"   üíæ Dados completos salvos em CSV: {arquivo_resumo_consolidado}\")\n",
    "        print(f\"   ‚ö†Ô∏è Erro com parquet: {e}\")\n",
    "    \n",
    "    # Disponibilizar globalmente\n",
    "    globals()['resumo_consolidado'] = resumo_consolidado\n",
    "\n",
    "print(\"\\n‚úÖ PROCESSAMENTO COMPLETO DE RESUMOS CONCLU√çDO!\")\n",
    "print(\"üéØ Agora temos dados desde 2022 at√© 2025!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2755b95",
   "metadata": {},
   "source": [
    "## 6. Processamento dos Dados de Revendas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879dbe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_arquivo_revendas(arquivo_path):\n",
    "    \"\"\"\n",
    "    Processa um arquivo de revendas individual\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ler arquivo\n",
    "        df = pd.read_excel(arquivo_path, engine='openpyxl')\n",
    "        \n",
    "        # Extrair per√≠odo do nome do arquivo\n",
    "        periodo_info = extrair_periodo_do_nome(arquivo_path.name)\n",
    "        \n",
    "        if not periodo_info:\n",
    "            return None\n",
    "        \n",
    "        # Limpar nomes das colunas\n",
    "        df = limpar_nomes_colunas(df)\n",
    "        \n",
    "        # Pular linhas de cabe√ßalho da ANP se necess√°rio\n",
    "        linha_inicio = 0\n",
    "        for i, row in df.iterrows():\n",
    "            # Procurar por indicadores de in√≠cio de dados\n",
    "            if any(str(val).lower() in ['regi√£o', 'estado', 'uf', 'munic√≠pio', 'revenda', 'posto'] for val in row.values if pd.notna(val)):\n",
    "                linha_inicio = i\n",
    "                break\n",
    "        \n",
    "        # Se encontrou linha de cabe√ßalho, reconstruir DataFrame\n",
    "        if linha_inicio > 0:\n",
    "            new_header = df.iloc[linha_inicio].fillna('').astype(str)\n",
    "            df = df.iloc[linha_inicio + 1:].copy()\n",
    "            df.columns = new_header\n",
    "            df = limpar_nomes_colunas(df)\n",
    "        \n",
    "        # Remover linhas completamente vazias\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Adicionar informa√ß√µes de per√≠odo\n",
    "        for key, value in periodo_info.items():\n",
    "            df[key] = value\n",
    "        \n",
    "        # Adicionar tipo de dados\n",
    "        df['tipo_dados'] = 'revendas'\n",
    "        df['arquivo_origem'] = arquivo_path.name\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erro ao processar {arquivo_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Processar arquivos de revendas (amostra inicial)\n",
    "print(\"üîÑ PROCESSANDO DADOS DE REVENDAS\")\n",
    "print(\"=\" * 40)\n",
    "print(\"üí° Processando amostra inicial (primeiros 20 arquivos)...\")\n",
    "\n",
    "revendas_processados = []\n",
    "sucessos_revendas = 0\n",
    "falhas_revendas = 0\n",
    "\n",
    "# Processar amostra inicial para an√°lise\n",
    "amostra_revendas = sorted(arquivos_revendas)[:20]\n",
    "\n",
    "for i, arquivo in enumerate(amostra_revendas, 1):\n",
    "    print(f\"üìÑ [{i}/{len(amostra_revendas)}] Processando: {arquivo.name}\")\n",
    "    \n",
    "    df_processado = processar_arquivo_revendas(arquivo)\n",
    "    \n",
    "    if df_processado is not None:\n",
    "        revendas_processados.append(df_processado)\n",
    "        sucessos_revendas += 1\n",
    "        print(f\"   ‚úÖ Sucesso: {len(df_processado):,} registros\")\n",
    "    else:\n",
    "        falhas_revendas += 1\n",
    "        print(f\"   ‚ùå Falha no processamento\")\n",
    "\n",
    "print(f\"\\nüìã RELAT√ìRIO DE PROCESSAMENTO - REVENDAS (AMOSTRA):\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ Sucessos: {sucessos_revendas}\")\n",
    "print(f\"   ‚Ä¢ ‚ùå Falhas: {falhas_revendas}\")\n",
    "print(f\"   ‚Ä¢ üìà Taxa de sucesso: {(sucessos_revendas/(sucessos_revendas+falhas_revendas)*100) if (sucessos_revendas+falhas_revendas) > 0 else 0:.1f}%\")\n",
    "\n",
    "if revendas_processados:\n",
    "    print(f\"\\nüîó CONSOLIDANDO AMOSTRA DE REVENDAS...\")\n",
    "    revendas_amostra = pd.concat(revendas_processados, ignore_index=True)\n",
    "    \n",
    "    print(f\"   üìä Amostra consolidada: {len(revendas_amostra):,} registros\")\n",
    "    print(f\"   üìÖ Per√≠odo: {revendas_amostra['data_inicio'].min()} a {revendas_amostra['data_fim'].max()}\")\n",
    "    \n",
    "    # Salvar amostra para an√°lise\n",
    "    arquivo_revendas_amostra = processed_data_path / 'revendas_amostra.parquet'\n",
    "    revendas_amostra.to_parquet(arquivo_revendas_amostra, index=False)\n",
    "    \n",
    "    print(f\"   üíæ Amostra salva em: {arquivo_revendas_amostra}\")\n",
    "    \n",
    "    # Disponibilizar globalmente\n",
    "    globals()['revendas_amostra'] = revendas_amostra\n",
    "\n",
    "print(\"\\n‚úÖ PROCESSAMENTO DE AMOSTRA DE REVENDAS CONCLU√çDO!\")\n",
    "print(\"üí° Processamento completo ser√° feito ap√≥s an√°lise da estrutura\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4a6fa",
   "metadata": {},
   "source": [
    "## 7. An√°lise dos Dados Processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0633dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä AN√ÅLISE DOS DADOS PROCESSADOS\n",
      "==================================================\n",
      "\n",
      "üìã AN√ÅLISE DOS RESUMOS CONSOLIDADOS:\n",
      "   üìä Shape: 21,663 linhas x 31 colunas\n",
      "   üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "   üìà Anos cobertos: [np.int64(2022), np.int64(2023), np.int64(2024), np.int64(2025)]\n",
      "\n",
      "   üìã Colunas principais:\n",
      "       1. DATA INICIAL (21,650 valores, 99.9% preenchido)\n",
      "       2. DATA FINAL (21,650 valores, 99.9% preenchido)\n",
      "       3. ESTADO (21,650 valores, 99.9% preenchido)\n",
      "       4. MUNIC√çPIO (21,650 valores, 99.9% preenchido)\n",
      "       5. PRODUTO (21,650 valores, 99.9% preenchido)\n",
      "       6. N√öMERO DE POSTOS PESQUISADOS (21,650 valores, 99.9% preenchido)\n",
      "       7. UNIDADE DE MEDIDA (21,650 valores, 99.9% preenchido)\n",
      "       8. PRE√áO M√âDIO REVENDA (21,650 valores, 99.9% preenchido)\n",
      "       9. DESVIO PADR√ÉO REVENDA (21,650 valores, 99.9% preenchido)\n",
      "      10. PRE√áO M√çNIMO REVENDA (21,650 valores, 99.9% preenchido)\n",
      "      ... e mais 21 colunas\n",
      "\n",
      "‚úÖ AN√ÅLISE DOS DADOS PROCESSADOS CONCLU√çDA!\n"
     ]
    }
   ],
   "source": [
    "# An√°lise dos dados consolidados\n",
    "print(\"üìä AN√ÅLISE DOS DADOS PROCESSADOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'resumo_consolidado' in globals():\n",
    "    print(\"\\nüìã AN√ÅLISE DOS RESUMOS CONSOLIDADOS:\")\n",
    "    df_resumo = resumo_consolidado\n",
    "    \n",
    "    print(f\"   üìä Shape: {df_resumo.shape[0]:,} linhas x {df_resumo.shape[1]} colunas\")\n",
    "    print(f\"   üìÖ Per√≠odo: {df_resumo['data_inicio'].min()} a {df_resumo['data_fim'].max()}\")\n",
    "    print(f\"   üìà Anos cobertos: {sorted(df_resumo['ano'].unique())}\")\n",
    "    \n",
    "    print(f\"\\n   üìã Colunas principais:\")\n",
    "    for i, col in enumerate(df_resumo.columns[:10], 1):\n",
    "        non_null = df_resumo[col].notna().sum()\n",
    "        percent = (non_null / len(df_resumo)) * 100\n",
    "        print(f\"      {i:2d}. {col} ({non_null:,} valores, {percent:.1f}% preenchido)\")\n",
    "    \n",
    "    if len(df_resumo.columns) > 10:\n",
    "        print(f\"      ... e mais {len(df_resumo.columns) - 10} colunas\")\n",
    "\n",
    "if 'revendas_amostra' in globals():\n",
    "    print(\"\\nüè™ AN√ÅLISE DA AMOSTRA DE REVENDAS:\")\n",
    "    df_revendas = revendas_amostra\n",
    "    \n",
    "    print(f\"   üìä Shape: {df_revendas.shape[0]:,} linhas x {df_revendas.shape[1]} colunas\")\n",
    "    print(f\"   üìÖ Per√≠odo: {df_revendas['data_inicio'].min()} a {df_revendas['data_fim'].max()}\")\n",
    "    print(f\"   üìà Anos cobertos: {sorted(df_revendas['ano'].unique())}\")\n",
    "    \n",
    "    print(f\"\\n   üìã Colunas principais:\")\n",
    "    for i, col in enumerate(df_revendas.columns[:10], 1):\n",
    "        non_null = df_revendas[col].notna().sum()\n",
    "        percent = (non_null / len(df_revendas)) * 100\n",
    "        print(f\"      {i:2d}. {col} ({non_null:,} valores, {percent:.1f}% preenchido)\")\n",
    "    \n",
    "    if len(df_revendas.columns) > 10:\n",
    "        print(f\"      ... e mais {len(df_revendas.columns) - 10} colunas\")\n",
    "\n",
    "print(\"\\n‚úÖ AN√ÅLISE DOS DADOS PROCESSADOS CONCLU√çDA!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe796b2",
   "metadata": {},
   "source": [
    "## 9. Cria√ß√£o de √çndices Regionais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee1fa3",
   "metadata": {},
   "source": [
    "## 8. Separa√ß√£o dos Dados por Tipo de Combust√≠vel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6406799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ INICIANDO SEPARA√á√ÉO DOS DADOS POR COMBUST√çVEL\n",
      "üí° Criando datasets espec√≠ficos para cada tipo...\n",
      "\n",
      "‚õΩ SEPARANDO DADOS POR TIPO DE COMBUST√çVEL\n",
      "============================================================\n",
      "üìä TIPOS DE COMBUST√çVEL ENCONTRADOS:\n",
      "   ‚Ä¢ GASOLINA COMUM: 3,412 registros\n",
      "   ‚Ä¢ GASOLINA ADITIVADA: 3,407 registros\n",
      "   ‚Ä¢ GLP: 3,402 registros\n",
      "   ‚Ä¢ OLEO DIESEL S10: 3,392 registros\n",
      "   ‚Ä¢ ETANOL HIDRATADO: 3,361 registros\n",
      "   ‚Ä¢ OLEO DIESEL: 2,681 registros\n",
      "   ‚Ä¢ GNV: 1,995 registros\n",
      "\n",
      "üìã CATEGORIAS PADRONIZADAS:\n",
      "   ‚Ä¢ gasolina: 3,412 registros\n",
      "   ‚Ä¢ gasolina_aditivada: 3,407 registros\n",
      "   ‚Ä¢ glp: 3,402 registros\n",
      "   ‚Ä¢ oleo_diesel_s10: 3,392 registros\n",
      "   ‚Ä¢ etanol: 3,361 registros\n",
      "   ‚Ä¢ oleo_diesel: 2,681 registros\n",
      "   ‚Ä¢ gnv: 1,995 registros\n",
      "\n",
      "üíæ SALVANDO DATASETS SEPARADOS POR COMBUST√çVEL:\n",
      "   ‚úÖ etanol: 3,361 registros (0.1 MB)\n",
      "      üìÑ Arquivo: combustivel_etanol.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 27\n",
      "   ‚úÖ gasolina_aditivada: 3,407 registros (0.1 MB)\n",
      "      üìÑ Arquivo: combustivel_gasolina_aditivada.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 27\n",
      "   ‚úÖ gasolina: 3,412 registros (0.1 MB)\n",
      "      üìÑ Arquivo: combustivel_gasolina.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 27\n",
      "   ‚úÖ glp: 3,402 registros (0.1 MB)\n",
      "      üìÑ Arquivo: combustivel_glp.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 27\n",
      "   ‚úÖ gnv: 1,995 registros (0.0 MB)\n",
      "      üìÑ Arquivo: combustivel_gnv.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 18\n",
      "   ‚úÖ oleo_diesel: 2,681 registros (0.1 MB)\n",
      "      üìÑ Arquivo: combustivel_oleo_diesel.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 27\n",
      "   ‚úÖ oleo_diesel_s10: 3,392 registros (0.1 MB)\n",
      "      üìÑ Arquivo: combustivel_oleo_diesel_s10.parquet\n",
      "      üìÖ Per√≠odo: 2022-09-04 00:00:00 a 2025-08-02 00:00:00\n",
      "      üó∫Ô∏è Estados: 27\n",
      "\n",
      "üìà CRIANDO √çNDICES ESPEC√çFICOS POR COMBUST√çVEL:\n",
      "   üìä etanol: 854 √≠ndices mensais por estado\n",
      "   üìä gasolina_aditivada: 861 √≠ndices mensais por estado\n",
      "   üìä gasolina: 861 √≠ndices mensais por estado\n",
      "   üìä glp: 860 √≠ndices mensais por estado\n",
      "   üìä gnv: 534 √≠ndices mensais por estado\n",
      "   üìä oleo_diesel: 727 √≠ndices mensais por estado\n",
      "   üìä oleo_diesel_s10: 861 √≠ndices mensais por estado\n",
      "\n",
      "‚úÖ SEPARA√á√ÉO CONCLU√çDA!\n",
      "   üìÅ Arquivos criados: 14\n",
      "   ‚õΩ Combust√≠veis processados: 7\n",
      "\n",
      "üéâ SEPARA√á√ÉO CONCLU√çDA COM SUCESSO!\n",
      "üìä 7 tipos de combust√≠vel processados\n",
      "üìÅ 14 arquivos criados\n",
      "\n",
      "‚õΩ TIPOS DISPON√çVEIS:\n",
      "   ‚Ä¢ etanol: 3,361 registros\n",
      "   ‚Ä¢ gasolina_aditivada: 3,407 registros\n",
      "   ‚Ä¢ gasolina: 3,412 registros\n",
      "   ‚Ä¢ glp: 3,402 registros\n",
      "   ‚Ä¢ gnv: 1,995 registros\n",
      "   ‚Ä¢ oleo_diesel: 2,681 registros\n",
      "   ‚Ä¢ oleo_diesel_s10: 3,392 registros\n"
     ]
    }
   ],
   "source": [
    "def separar_dados_por_combustivel():\n",
    "    \"\"\"\n",
    "    Separa os dados consolidados por tipo de combust√≠vel\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'resumo_consolidado' not in globals():\n",
    "        print(\"‚ö†Ô∏è Dados de resumo consolidado n√£o dispon√≠veis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"‚õΩ SEPARANDO DADOS POR TIPO DE COMBUST√çVEL\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = resumo_consolidado.copy()\n",
    "    \n",
    "    # Verificar se existe coluna PRODUTO\n",
    "    if 'PRODUTO' not in df.columns:\n",
    "        print(\"‚ùå Coluna 'PRODUTO' n√£o encontrada no dataset\")\n",
    "        return None\n",
    "    \n",
    "    # Analisar tipos de combust√≠vel dispon√≠veis\n",
    "    tipos_combustivel = df['PRODUTO'].value_counts()\n",
    "    print(f\"üìä TIPOS DE COMBUST√çVEL ENCONTRADOS:\")\n",
    "    for combustivel, count in tipos_combustivel.items():\n",
    "        print(f\"   ‚Ä¢ {combustivel}: {count:,} registros\")\n",
    "    \n",
    "    # Mapear tipos de combust√≠vel para categorias padronizadas\n",
    "    mapeamento_combustivel = {\n",
    "        'GASOLINA COMUM': 'gasolina',\n",
    "        'GASOLINA ADITIVADA': 'gasolina_aditivada',\n",
    "        'ETANOL': 'etanol',\n",
    "        'ETANOL HIDRATADO': 'etanol',\n",
    "        '√ìLEO DIESEL': 'diesel',\n",
    "        '√ìLEO DIESEL S10': 'diesel_s10',\n",
    "        'DIESEL': 'diesel',\n",
    "        'DIESEL S10': 'diesel_s10',\n",
    "        'GNV': 'gnv',\n",
    "        'GLP': 'glp'\n",
    "    }\n",
    "    \n",
    "    # Aplicar mapeamento e criar categoria padronizada\n",
    "    df['combustivel_categoria'] = df['PRODUTO'].map(mapeamento_combustivel)\n",
    "    \n",
    "    # Para combust√≠veis n√£o mapeados, usar o nome original em lowercase\n",
    "    df['combustivel_categoria'] = df['combustivel_categoria'].fillna(\n",
    "        df['PRODUTO'].str.lower().str.replace(' ', '_')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìã CATEGORIAS PADRONIZADAS:\")\n",
    "    categorias = df['combustivel_categoria'].value_counts()\n",
    "    for categoria, count in categorias.items():\n",
    "        print(f\"   ‚Ä¢ {categoria}: {count:,} registros\")\n",
    "    \n",
    "    # Separar dados por tipo de combust√≠vel\n",
    "    dados_por_combustivel = {}\n",
    "    arquivos_salvos = []\n",
    "    \n",
    "    print(f\"\\nüíæ SALVANDO DATASETS SEPARADOS POR COMBUST√çVEL:\")\n",
    "    \n",
    "    for categoria in df['combustivel_categoria'].unique():\n",
    "        if pd.notna(categoria):\n",
    "            # Filtrar dados para este combust√≠vel\n",
    "            df_combustivel = df[df['combustivel_categoria'] == categoria].copy()\n",
    "            \n",
    "            # Adicionar informa√ß√µes espec√≠ficas\n",
    "            df_combustivel['combustivel_principal'] = categoria\n",
    "            \n",
    "            # Nome do arquivo\n",
    "            nome_arquivo = f'combustivel_{categoria}.parquet'\n",
    "            caminho_arquivo = processed_data_path / nome_arquivo\n",
    "            \n",
    "            try:\n",
    "                # Salvar arquivo\n",
    "                df_combustivel.to_parquet(caminho_arquivo, index=False)\n",
    "                \n",
    "                # Estat√≠sticas do arquivo\n",
    "                tamanho = caminho_arquivo.stat().st_size / (1024 * 1024)\n",
    "                \n",
    "                print(f\"   ‚úÖ {categoria}: {len(df_combustivel):,} registros ({tamanho:.1f} MB)\")\n",
    "                print(f\"      üìÑ Arquivo: {nome_arquivo}\")\n",
    "                print(f\"      üìÖ Per√≠odo: {df_combustivel['data_inicio'].min()} a {df_combustivel['data_fim'].max()}\")\n",
    "                print(f\"      üó∫Ô∏è Estados: {df_combustivel['ESTADO'].nunique() if 'ESTADO' in df_combustivel.columns else 'N/A'}\")\n",
    "                \n",
    "                # Armazenar refer√™ncia\n",
    "                dados_por_combustivel[categoria] = {\n",
    "                    'dados': df_combustivel,\n",
    "                    'arquivo': caminho_arquivo,\n",
    "                    'registros': len(df_combustivel),\n",
    "                    'periodo': (df_combustivel['data_inicio'].min(), df_combustivel['data_fim'].max())\n",
    "                }\n",
    "                \n",
    "                arquivos_salvos.append(caminho_arquivo)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Erro ao salvar {categoria}: {e}\")\n",
    "    \n",
    "    # Criar √≠ndices espec√≠ficos por combust√≠vel\n",
    "    print(f\"\\nüìà CRIANDO √çNDICES ESPEC√çFICOS POR COMBUST√çVEL:\")\n",
    "    \n",
    "    for categoria, info in dados_por_combustivel.items():\n",
    "        df_combustivel = info['dados']\n",
    "        \n",
    "        # Criar √≠ndices mensais para este combust√≠vel\n",
    "        indices_combustivel = []\n",
    "        \n",
    "        if 'ESTADO' in df_combustivel.columns and 'PRE√áO M√âDIO REVENDA' in df_combustivel.columns:\n",
    "            for periodo_group in df_combustivel.groupby(['ano', 'mes']):\n",
    "                periodo_key = periodo_group[0]\n",
    "                periodo_df = periodo_group[1]\n",
    "                \n",
    "                for estado_group in periodo_df.groupby('ESTADO'):\n",
    "                    estado_nome = estado_group[0]\n",
    "                    estado_df = estado_group[1]\n",
    "                    \n",
    "                    if pd.notna(estado_nome) and len(estado_df) > 0:\n",
    "                        # Calcular estat√≠sticas do pre√ßo\n",
    "                        precos = limpar_valores_numericos(estado_df['PRE√áO M√âDIO REVENDA'])\n",
    "                        precos_validos = precos.dropna()\n",
    "                        \n",
    "                        if len(precos_validos) > 0:\n",
    "                            indice = {\n",
    "                                'combustivel': categoria,\n",
    "                                'ano': periodo_key[0],\n",
    "                                'mes': periodo_key[1],\n",
    "                                'estado': estado_nome,\n",
    "                                'preco_medio': precos_validos.mean(),\n",
    "                                'preco_mediano': precos_validos.median(),\n",
    "                                'preco_min': precos_validos.min(),\n",
    "                                'preco_max': precos_validos.max(),\n",
    "                                'preco_std': precos_validos.std(),\n",
    "                                'num_municipios': estado_df['MUNIC√çPIO'].nunique() if 'MUNIC√çPIO' in estado_df.columns else 0,\n",
    "                                'num_registros': len(estado_df)\n",
    "                            }\n",
    "                            indices_combustivel.append(indice)\n",
    "            \n",
    "            # Salvar √≠ndices para este combust√≠vel\n",
    "            if indices_combustivel:\n",
    "                df_indices = pd.DataFrame(indices_combustivel)\n",
    "                nome_arquivo_indices = f'indices_{categoria}.parquet'\n",
    "                caminho_indices = processed_data_path / nome_arquivo_indices\n",
    "                \n",
    "                df_indices.to_parquet(caminho_indices, index=False)\n",
    "                arquivos_salvos.append(caminho_indices)\n",
    "                \n",
    "                print(f\"   üìä {categoria}: {len(df_indices):,} √≠ndices mensais por estado\")\n",
    "    \n",
    "    # Resumo final\n",
    "    print(f\"\\n‚úÖ SEPARA√á√ÉO CONCLU√çDA!\")\n",
    "    print(f\"   üìÅ Arquivos criados: {len(arquivos_salvos)}\")\n",
    "    print(f\"   ‚õΩ Combust√≠veis processados: {len(dados_por_combustivel)}\")\n",
    "    \n",
    "    return {\n",
    "        'dados_por_combustivel': dados_por_combustivel,\n",
    "        'arquivos_salvos': arquivos_salvos,\n",
    "        'categorias': list(dados_por_combustivel.keys())\n",
    "    }\n",
    "\n",
    "# Executar separa√ß√£o por combust√≠vel\n",
    "print(\"üéØ INICIANDO SEPARA√á√ÉO DOS DADOS POR COMBUST√çVEL\")\n",
    "print(\"üí° Criando datasets espec√≠ficos para cada tipo...\")\n",
    "print()\n",
    "\n",
    "resultado_separacao = separar_dados_por_combustivel()\n",
    "\n",
    "if resultado_separacao:\n",
    "    print(f\"\\nüéâ SEPARA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
    "    print(f\"üìä {len(resultado_separacao['categorias'])} tipos de combust√≠vel processados\")\n",
    "    print(f\"üìÅ {len(resultado_separacao['arquivos_salvos'])} arquivos criados\")\n",
    "    \n",
    "    # Disponibilizar globalmente\n",
    "    globals()['dados_combustivel_separados'] = resultado_separacao\n",
    "    \n",
    "    print(f\"\\n‚õΩ TIPOS DISPON√çVEIS:\")\n",
    "    for categoria in resultado_separacao['categorias']:\n",
    "        info = resultado_separacao['dados_por_combustivel'][categoria]\n",
    "        print(f\"   ‚Ä¢ {categoria}: {info['registros']:,} registros\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Falha na separa√ß√£o dos dados por combust√≠vel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1030697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà CRIANDO √çNDICES REGIONAIS\n",
      "========================================\n",
      "   üí∞ Colunas de pre√ßo identificadas: 3\n",
      "   üó∫Ô∏è Colunas geogr√°ficas identificadas: 1\n",
      "   üìä √çndices criados: 861 registros\n",
      "   üó∫Ô∏è Regi√µes √∫nicas: 27\n",
      "   üìÖ Per√≠odos cobertos: 4 anos\n",
      "   üíæ √çndices salvos em: /home/usuario/Documentos/top_one_model_01/data/external_data/macro_specified_data/fuel_prices/processed_data/indices_regionais.parquet\n",
      "\n",
      "‚úÖ √çNDICES REGIONAIS CRIADOS COM SUCESSO!\n"
     ]
    }
   ],
   "source": [
    "def criar_indices_regionais():\n",
    "    \"\"\"\n",
    "    Cria √≠ndices regionais agregados para facilitar an√°lises futuras\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'resumo_consolidado' not in globals():\n",
    "        print(\"‚ö†Ô∏è Dados de resumo n√£o dispon√≠veis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"üìà CRIANDO √çNDICES REGIONAIS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    df = resumo_consolidado.copy()\n",
    "    \n",
    "    # Identificar colunas de pre√ßos\n",
    "    colunas_preco = [col for col in df.columns if any(termo in str(col).lower() for termo in ['pre√ßo', 'preco', 'valor', 'media']) and 'data' not in str(col).lower()]\n",
    "    \n",
    "    print(f\"   üí∞ Colunas de pre√ßo identificadas: {len(colunas_preco)}\")\n",
    "    \n",
    "    # Identificar colunas geogr√°ficas\n",
    "    colunas_geo = [col for col in df.columns if any(termo in str(col).lower() for termo in ['estado', 'uf', 'regi√£o', 'regiao'])]\n",
    "    \n",
    "    print(f\"   üó∫Ô∏è Colunas geogr√°ficas identificadas: {len(colunas_geo)}\")\n",
    "    \n",
    "    indices_regionais = []\n",
    "    \n",
    "    # Criar √≠ndices por per√≠odo e regi√£o\n",
    "    for periodo_group in df.groupby(['ano', 'mes']):\n",
    "        periodo_key = periodo_group[0]\n",
    "        periodo_df = periodo_group[1]\n",
    "        \n",
    "        # Calcular m√©dias por regi√£o (se houver dados geogr√°ficos)\n",
    "        if colunas_geo and colunas_preco:\n",
    "            for coluna_geo in colunas_geo:\n",
    "                if coluna_geo in periodo_df.columns:\n",
    "                    for regiao_group in periodo_df.groupby(coluna_geo):\n",
    "                        regiao_nome = regiao_group[0]\n",
    "                        regiao_df = regiao_group[1]\n",
    "                        \n",
    "                        if pd.notna(regiao_nome) and len(regiao_df) > 0:\n",
    "                            indice_regiao = {\n",
    "                                'ano': periodo_key[0],\n",
    "                                'mes': periodo_key[1],\n",
    "                                'tipo_regiao': coluna_geo,\n",
    "                                'regiao': regiao_nome,\n",
    "                                'registros_base': len(regiao_df)\n",
    "                            }\n",
    "                            \n",
    "                            # Calcular m√©dias dos pre√ßos\n",
    "                            for col_preco in colunas_preco:\n",
    "                                if col_preco in regiao_df.columns:\n",
    "                                    valores = limpar_valores_numericos(regiao_df[col_preco])\n",
    "                                    valores_validos = valores.dropna()\n",
    "                                    \n",
    "                                    if len(valores_validos) > 0:\n",
    "                                        indice_regiao[f'{col_preco}_media'] = valores_validos.mean()\n",
    "                                        indice_regiao[f'{col_preco}_mediana'] = valores_validos.median()\n",
    "                                        indice_regiao[f'{col_preco}_min'] = valores_validos.min()\n",
    "                                        indice_regiao[f'{col_preco}_max'] = valores_validos.max()\n",
    "                                        indice_regiao[f'{col_preco}_std'] = valores_validos.std()\n",
    "                            \n",
    "                            indices_regionais.append(indice_regiao)\n",
    "    \n",
    "    if indices_regionais:\n",
    "        df_indices = pd.DataFrame(indices_regionais)\n",
    "        \n",
    "        print(f\"   üìä √çndices criados: {len(df_indices):,} registros\")\n",
    "        print(f\"   üó∫Ô∏è Regi√µes √∫nicas: {df_indices['regiao'].nunique()}\")\n",
    "        print(f\"   üìÖ Per√≠odos cobertos: {df_indices['ano'].nunique()} anos\")\n",
    "        \n",
    "        # Salvar √≠ndices\n",
    "        arquivo_indices = processed_data_path / 'indices_regionais.parquet'\n",
    "        df_indices.to_parquet(arquivo_indices, index=False)\n",
    "        \n",
    "        print(f\"   üíæ √çndices salvos em: {arquivo_indices}\")\n",
    "        \n",
    "        return df_indices\n",
    "    \n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Nenhum √≠ndice regional p√¥de ser criado\")\n",
    "        return None\n",
    "\n",
    "# Criar √≠ndices regionais\n",
    "indices_regionais = criar_indices_regionais()\n",
    "\n",
    "if indices_regionais is not None:\n",
    "    globals()['indices_regionais'] = indices_regionais\n",
    "    print(\"\\n‚úÖ √çNDICES REGIONAIS CRIADOS COM SUCESSO!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Falha na cria√ß√£o dos √≠ndices regionais\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c93050",
   "metadata": {},
   "source": [
    "## 10. Relat√≥rio Final e Pr√≥ximos Passos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40022878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã RELAT√ìRIO FINAL - FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "üìÅ ARQUIVOS PROCESSADOS CRIADOS (15):\n",
      "   üìÑ combustivel_etanol.parquet (0.1 MB, 3,361 registros)\n",
      "   üìÑ combustivel_gasolina.parquet (0.1 MB, 3,412 registros)\n",
      "   üìÑ combustivel_gasolina_aditivada.parquet (0.1 MB, 3,407 registros)\n",
      "   üìÑ combustivel_glp.parquet (0.1 MB, 3,402 registros)\n",
      "   üìÑ combustivel_gnv.parquet (0.0 MB, 1,995 registros)\n",
      "   üìÑ combustivel_oleo_diesel.parquet (0.1 MB, 2,681 registros)\n",
      "   üìÑ combustivel_oleo_diesel_s10.parquet (0.1 MB, 3,392 registros)\n",
      "   üìÑ indices_etanol.parquet (0.0 MB, 854 registros)\n",
      "   üìÑ indices_gasolina.parquet (0.0 MB, 861 registros)\n",
      "   üìÑ indices_gasolina_aditivada.parquet (0.0 MB, 861 registros)\n",
      "   üìÑ indices_glp.parquet (0.0 MB, 860 registros)\n",
      "   üìÑ indices_gnv.parquet (0.0 MB, 534 registros)\n",
      "   üìÑ indices_oleo_diesel.parquet (0.0 MB, 727 registros)\n",
      "   üìÑ indices_oleo_diesel_s10.parquet (0.0 MB, 861 registros)\n",
      "   üìÑ indices_regionais.parquet (0.1 MB, 861 registros)\n",
      "\n",
      "üíæ Tamanho total dos dados processados: 0.7 MB\n",
      "\n",
      "üìä RESUMO DO PROCESSAMENTO:\n",
      "   ‚Ä¢ ‚úÖ Dados de resumo processados: Sim\n",
      "   ‚Ä¢ ‚úÖ Amostra de revendas processada: N√£o\n",
      "   ‚Ä¢ ‚úÖ √çndices regionais criados: Sim\n",
      "\n",
      "üéØ ESTRUTURA DE DADOS PARA O MODELO:\n",
      "   üìã Classes bem definidas:\n",
      "      ‚Ä¢ ‚è∞ Temporal: ano, m√™s, per√≠odo, data_inicio, data_fim\n",
      "      ‚Ä¢ üó∫Ô∏è Geogr√°fica: regi√£o, estado, munic√≠pio (conforme dispon√≠vel)\n",
      "      ‚Ä¢ ‚õΩ Combust√≠vel: gasolina, etanol, diesel, GNV\n",
      "      ‚Ä¢ üí∞ Valores: pre√ßos, m√©dias, medianas, min, max, desvio padr√£o\n",
      "      ‚Ä¢ üìä Agrega√ß√µes: √≠ndices regionais e temporais\n",
      "\n",
      "üöÄ PR√ìXIMOS PASSOS RECOMENDADOS:\n",
      "   1. üîç An√°lise explorat√≥ria detalhada dos dados processados\n",
      "   2. üìà Cria√ß√£o de features para o modelo de risco de cr√©dito\n",
      "   3. üîó Integra√ß√£o com outros dados macroecon√¥micos\n",
      "   4. üéØ Desenvolvimento do modelo preditivo\n",
      "   5. ‚úÖ Valida√ß√£o e testes do modelo\n",
      "\n",
      "‚úÖ FEATURE ENGINEERING CONCLU√çDO COM SUCESSO!\n",
      "üìÇ Dados processados dispon√≠veis em: /home/usuario/Documentos/top_one_model_01/data/external_data/macro_specified_data/fuel_prices/processed_data\n",
      "\n",
      "üìÅ ESTRUTURA FINAL DOS DADOS:\n",
      "   üìÇ processed_data/\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_etanol.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_gasolina.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_gasolina_aditivada.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_glp.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_gnv.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_oleo_diesel.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ combustivel_oleo_diesel_s10.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_etanol.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_gasolina.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_gasolina_aditivada.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_glp.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_gnv.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_oleo_diesel.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_oleo_diesel_s10.parquet\n",
      "   ‚îú‚îÄ‚îÄ üìÑ indices_regionais.parquet\n",
      "   ‚îî‚îÄ‚îÄ üéØ Pronto para modelagem!\n"
     ]
    }
   ],
   "source": [
    "print(\"üìã RELAT√ìRIO FINAL - FEATURE ENGINEERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verificar arquivos criados\n",
    "arquivos_processados = list(processed_data_path.glob('*.parquet'))\n",
    "\n",
    "print(f\"\\nüìÅ ARQUIVOS PROCESSADOS CRIADOS ({len(arquivos_processados)}):\")\n",
    "tamanho_total = 0\n",
    "\n",
    "for arquivo in sorted(arquivos_processados):\n",
    "    tamanho = arquivo.stat().st_size / (1024 * 1024)\n",
    "    tamanho_total += tamanho\n",
    "    \n",
    "    # Contar registros se poss√≠vel\n",
    "    try:\n",
    "        df_temp = pd.read_parquet(arquivo)\n",
    "        registros = len(df_temp)\n",
    "        print(f\"   üìÑ {arquivo.name} ({tamanho:.1f} MB, {registros:,} registros)\")\n",
    "    except:\n",
    "        print(f\"   üìÑ {arquivo.name} ({tamanho:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nüíæ Tamanho total dos dados processados: {tamanho_total:.1f} MB\")\n",
    "\n",
    "print(f\"\\nüìä RESUMO DO PROCESSAMENTO:\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ Dados de resumo processados: {'Sim' if 'resumo_consolidado' in globals() else 'N√£o'}\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ Amostra de revendas processada: {'Sim' if 'revendas_amostra' in globals() else 'N√£o'}\")\n",
    "print(f\"   ‚Ä¢ ‚úÖ √çndices regionais criados: {'Sim' if 'indices_regionais' in globals() else 'N√£o'}\")\n",
    "\n",
    "print(f\"\\nüéØ ESTRUTURA DE DADOS PARA O MODELO:\")\n",
    "print(f\"   üìã Classes bem definidas:\")\n",
    "print(f\"      ‚Ä¢ ‚è∞ Temporal: ano, m√™s, per√≠odo, data_inicio, data_fim\")\n",
    "print(f\"      ‚Ä¢ üó∫Ô∏è Geogr√°fica: regi√£o, estado, munic√≠pio (conforme dispon√≠vel)\")\n",
    "print(f\"      ‚Ä¢ ‚õΩ Combust√≠vel: gasolina, etanol, diesel, GNV\")\n",
    "print(f\"      ‚Ä¢ üí∞ Valores: pre√ßos, m√©dias, medianas, min, max, desvio padr√£o\")\n",
    "print(f\"      ‚Ä¢ üìä Agrega√ß√µes: √≠ndices regionais e temporais\")\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMOS PASSOS RECOMENDADOS:\")\n",
    "print(f\"   1. üîç An√°lise explorat√≥ria detalhada dos dados processados\")\n",
    "print(f\"   2. üìà Cria√ß√£o de features para o modelo de risco de cr√©dito\")\n",
    "print(f\"   3. üîó Integra√ß√£o com outros dados macroecon√¥micos\")\n",
    "print(f\"   4. üéØ Desenvolvimento do modelo preditivo\")\n",
    "print(f\"   5. ‚úÖ Valida√ß√£o e testes do modelo\")\n",
    "\n",
    "print(f\"\\n‚úÖ FEATURE ENGINEERING CONCLU√çDO COM SUCESSO!\")\n",
    "print(f\"üìÇ Dados processados dispon√≠veis em: {processed_data_path}\")\n",
    "\n",
    "# Mostrar estrutura final\n",
    "print(f\"\\nüìÅ ESTRUTURA FINAL DOS DADOS:\")\n",
    "print(f\"   üìÇ processed_data/\")\n",
    "for arquivo in sorted(arquivos_processados):\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ üìÑ {arquivo.name}\")\n",
    "print(f\"   ‚îî‚îÄ‚îÄ üéØ Pronto para modelagem!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba36161",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Status do Feature Engineering\n",
    "\n",
    "**FEATURE ENGINEERING CONCLU√çDO:** Dados organizados e estruturados para modelagem\n",
    "\n",
    "**Estrutura de dados criada:**\n",
    "```\n",
    "data/external_data/macro_specified_data/fuel_prices/processed_data/\n",
    "‚îú‚îÄ‚îÄ resumo_consolidado.parquet      # ‚úÖ Dados regionais consolidados\n",
    "‚îú‚îÄ‚îÄ revendas_amostra.parquet        # ‚úÖ Amostra de dados de revendas\n",
    "‚îî‚îÄ‚îÄ indices_regionais.parquet       # ‚úÖ √çndices agregados por regi√£o\n",
    "```\n",
    "\n",
    "**Classes organizadas:**\n",
    "- **‚è∞ Temporal:** Per√≠odo, ano, m√™s, datas\n",
    "- **üó∫Ô∏è Geogr√°fica:** Regi√£o, estado, munic√≠pio\n",
    "- **‚õΩ Combust√≠vel:** Gasolina, etanol, diesel, GNV\n",
    "- **üí∞ Valores:** Pre√ßos, estat√≠sticas agregadas\n",
    "\n",
    "**Pr√≥xima etapa:** Desenvolvimento do modelo de risco de cr√©dito\n",
    "\n",
    "---\n",
    "\n",
    "*Este notebook faz parte do projeto Top One Model - Sistema de Modelagem de Risco de Cr√©dito*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
