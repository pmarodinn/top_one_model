# üéØ Top One Model - Sistema de Modelagem de Risco de Cr√©dito

## üìã Vis√£o Geral

Sistema avan√ßado de modelagem de risco de cr√©dito que vai al√©m da classifica√ß√£o bin√°ria tradicional, implementando um **espectro cont√≠nuo de risco** com 5 regi√µes e integra√ß√£o de dados macroecon√¥micos regionais via web scraping.

### üéØ Caracter√≠sticas Principais

- **Espectro de Risco Cont√≠nuo**: 5 regi√µes (Adimplente Pontual ‚Üí Inadimplente Total)
- **Dados Regionais**: Web scraping autom√°tico de combust√≠veis, utilities e indicadores econ√¥micos
- **Feature Engineering Avan√ßada**: Features sint√©ticas como "Estresse Financeiro"
- **Modelos M√∫ltiplos**: Baseline, XGBoost, LightGBM com arquitetura h√≠brida
- **Valida√ß√£o Temporal**: Backtesting robusto e detec√ß√£o de drift
- **Interpretabilidade**: LIME/SHAP para explica√ß√£o das predi√ß√µes
- **Interface Web**: Sistema interativo para classifica√ß√£o de novas pessoas

---

## üèóÔ∏è Estrutura do Projeto

```
top_one_model/
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ internal_data/          # Dataset interno (.xlsx)
‚îÇ   ‚îú‚îÄ‚îÄ external/              # Dados coletados via web scraping
‚îÇ   ‚îî‚îÄ‚îÄ processed/             # Dados processados finais
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_collection/       # üåê M√≥dulos de web scraping
‚îÇ   ‚îú‚îÄ‚îÄ data_engineering/      # üîß Engenharia de features
‚îÇ   ‚îú‚îÄ‚îÄ modeling/              # ü§ñ Modelos de ML
‚îÇ   ‚îú‚îÄ‚îÄ validation/            # ‚úÖ Valida√ß√£o e testes
‚îÇ   ‚îî‚îÄ‚îÄ prediction/            # üéØ Sistema de predi√ß√£o
‚îú‚îÄ‚îÄ üìÅ notebooks/              # üìä An√°lises explorat√≥rias
‚îú‚îÄ‚îÄ üìÅ models/                 # üíæ Modelos treinados
‚îú‚îÄ‚îÄ üìÅ config/                 # ‚öôÔ∏è Configura√ß√µes
‚îú‚îÄ‚îÄ üìÅ logs/                   # üìù Logs de execu√ß√£o
‚îú‚îÄ‚îÄ main_pipeline.py           # üöÄ Pipeline principal
‚îú‚îÄ‚îÄ requirements.txt           # üì¶ Depend√™ncias
‚îî‚îÄ‚îÄ README.md                  # üìñ Este arquivo
```

---

## ‚ö° Quick Start

### 1. Instala√ß√£o

```bash
# Clonar/navegar para o diret√≥rio do projeto
cd top_one_model/

# Instalar depend√™ncias
pip install -r requirements.txt

# Criar diret√≥rios necess√°rios
mkdir -p logs models data/processed
```

### 2. Preparar Dataset Interno

Coloque seu dataset interno em:
```
data/internal_data/dataset_interno_top_one.xlsx
```

**Colunas esperadas:**
- `cidade` ou `municipio`: Para associa√ß√£o com dados regionais
- `renda_mensal`, `divida_total`: Para feature "Estresse Financeiro"
- Colunas de hist√≥rico de pagamento (opcional - ser√£o simuladas se n√£o existirem)

### 3. Executar Pipeline

```bash
# An√°lise completa + Treinamento + Predi√ß√£o
python main_pipeline.py --mode all

# Ou executar etapas individuais:
python main_pipeline.py --mode analysis    # An√°lise e feature engineering
python main_pipeline.py --mode training    # Treinamento de modelos
python main_pipeline.py --mode prediction  # Sistema de predi√ß√£o
```

### 4. Interface Web (Opcional)

```bash
# Instalar Streamlit
pip install streamlit

# Executar interface
streamlit run src/prediction/prediction_system.py
```

---

## üîÑ Pipeline Detalhado

### Fase 1: An√°lise do Dataset Interno
- ‚úÖ Carregamento e valida√ß√£o do dataset (.xlsx)
- ‚úÖ An√°lise estat√≠stica descritiva
- ‚úÖ Identifica√ß√£o de colunas geogr√°ficas
- ‚úÖ Verifica√ß√£o de qualidade dos dados

### Fase 2: Coleta de Dados Regionais (Web Scraping)
- üåê **Combust√≠veis**: Gasolina, etanol, diesel por munic√≠pio
- ‚ö° **Utilities**: Energia el√©trica, √°gua, g√°s por regi√£o
- üìä **Indicadores**: PIB per capita, desemprego, cesta b√°sica
- üîÑ **Frequ√™ncia**: Configur√°vel (padr√£o: 45 dias)

### Fase 3: Engenharia de Features
- üîß **Integra√ß√£o**: Merge de dados internos + externos por cidade
- üí∞ **Feature Sint√©tica**: Estresse Financeiro = D√≠vida / (Renda - Custo Regional)
- üìà **Features Comportamentais**: Volatilidade de pagamentos, raz√£o produto/renda
- üèôÔ∏è **Features Regionais**: √çndices de custo de vida e poder de compra

### Fase 4: Modelagem (Arquitetura em Est√°gios)
- üìä **Baseline**: Regress√£o Log√≠stica Multinomial
- üöÄ **Ensemble**: XGBoost e LightGBM otimizados
- üß† **Opcional**: LSTM para extra√ß√£o de features sequenciais
- üéØ **Target**: Espectro cont√≠nuo 0-1 mapeado em 5 regi√µes

### Fase 5: Valida√ß√£o Temporal
- ‚è∞ **Valida√ß√£o Cruzada**: Sliding window temporal
- üß™ **Backtesting**: Hold-out dos √∫ltimos 6 meses
- üìä **M√©tricas**: Accuracy, F1, AUC, PSI para drift detection
- üîç **Monitoramento**: Detec√ß√£o autom√°tica de concept drift

### Fase 6: Sistema de Predi√ß√£o
- üë§ **Nova Pessoa**: Interface para entrada de dados
- üåê **Coleta Auto**: Dados regionais em tempo real
- üéØ **Classifica√ß√£o**: Espectro de risco + confian√ßa
- üîç **Explicabilidade**: Top 5 fatores de influ√™ncia

---

## üìä Espectro de Risco

| Score | Regi√£o | Descri√ß√£o | A√ß√£o Recomendada |
|-------|--------|-----------|------------------|
| 0.0-0.2 | üü¢ **Adimplente Pontual** | Pagamentos consistentes em dia | Ofertas de novos produtos |
| 0.2-0.4 | üü° **Adimplente Lucrativo** | Atrasos sistem√°ticos mas paga | Monitoramento preventivo |
| 0.4-0.6 | üü† **Risco de Abandono** | Cessa√ß√£o precoce de pagamentos | A√ß√£o de cobran√ßa imediata |
| 0.6-0.8 | üî¥ **Inadimplente Parcial** | Recupera√ß√£o parcial poss√≠vel | Estrat√©gia de renegocia√ß√£o |
| 0.8-1.0 | ‚ö´ **Inadimplente Total** | Perda total ou quase total | Provis√£o de perda |

---

## üõ†Ô∏è Configura√ß√µes

### Arquivo `config/config.yaml`

```yaml
# Configura√ß√µes de Web Scraping
scraping:
  frequency_days: 45
  combustiveis:
    frequency_days: 7
  utilities:
    frequency_days: 30

# Configura√ß√µes de Modelagem  
modeling:
  retrain_frequency_days: 45
  validation_window_months: 18

# Monitoramento
monitoring:
  drift_threshold: 0.15
  performance_window_days: 30
```

---

## üéØ Uso do Sistema de Predi√ß√£o

### Via C√≥digo Python

```python
from src.prediction.prediction_system import PersonRiskPredictor

# Inicializar preditor
predictor = PersonRiskPredictor()

# Dados da nova pessoa
person_info = {
    'nome': 'Maria Santos',
    'idade': 28,
    'renda_mensal': 3500.0,
    'divida_total': 6000.0,
    'cidade': 'Rio de Janeiro',
    'estado': 'RJ',
    'valor_produto': 2500.0,
    'tempo_emprego': 18
}

# Fazer predi√ß√£o completa
results = predictor.predict_new_person(person_info)

# Acessar resultados
prediction = results['prediction']
print(f"Regi√£o de Risco: {prediction['risk_region']}")
print(f"Score: {prediction['risk_score']:.3f}")
print(f"Confian√ßa: {max(prediction['probabilities']):.1%}")
```

### Via Interface Web

1. Execute: `streamlit run src/prediction/prediction_system.py`
2. Acesse: `http://localhost:8501`
3. Preencha o formul√°rio com dados da pessoa
4. Visualize resultados e explica√ß√µes interativas

---

## üìà Monitoramento e MLOps

### Sistema de Atualiza√ß√£o Cont√≠nua

- **Coleta Autom√°tica**: A cada 45 dias, novos dados s√£o coletados
- **Detec√ß√£o de Drift**: Testes KS e PSI para identificar mudan√ßas
- **Retreinamento**: Autom√°tico quando drift > 15%
- **A/B Testing**: Framework Champion/Challenger
- **Versionamento**: Modelos com rastreabilidade completa

### M√©tricas Monitoradas

- **Performance**: Accuracy, Precision, Recall, F1-Score
- **Estabilidade**: Population Stability Index (PSI)
- **Drift**: Kolmogorov-Smirnov test
- **Cobertura**: % dados regionais dispon√≠veis

---

## üîß Desenvolvimento e Customiza√ß√£o

### Adicionando Novas Fontes de Dados

1. Edite `src/data_collection/scraper.py`
2. Adicione nova fun√ß√£o de coleta
3. Atualize `run_full_collection()`
4. Configure frequ√™ncia em `config.yaml`

### Criando Novas Features

1. Edite `src/data_engineering/data_integration.py`
2. Adicione fun√ß√£o na classe `FeatureEngineer`
3. Inclua no pipeline `apply_feature_engineering_pipeline()`

### Adicionando Novos Modelos

1. Crie classe em `src/modeling/models.py`
2. Implemente m√©todos `train()` e `predict()`
3. Adicione ao pipeline principal

---

## ‚ö†Ô∏è Troubleshooting

### Problemas Comuns

**1. Erro de importa√ß√£o de bibliotecas**
```bash
pip install -r requirements.txt
```

**2. Dataset interno n√£o encontrado**
- Verifique se est√° em `data/internal_data/dataset_interno_top_one.xlsx`
- Confirme formato Excel (.xlsx)

**3. Falha no web scraping**
- Verifique conex√£o de internet
- Alguns sites podem ter mudado estrutura HTML
- Dados simulados ser√£o usados como fallback

**4. Modelo n√£o carregado**
- Execute primeiro: `python main_pipeline.py --mode training`
- Verifique se existe `models/best_model_*.pkl`

**5. Interface Streamlit n√£o abre**
```bash
pip install streamlit
streamlit run src/prediction/prediction_system.py
```

---

## üìö Refer√™ncias T√©cnicas

- **Aljadani et al. (2023)**: *Mathematical Modeling and Analysis of Credit Scoring Using the LIME Explainer*
- **Bielecki & Rutkowski (2001)**: *Credit Risk: Modeling, Valuation, and Hedging*
- **Crouhy, Galai, & Mark (2000)**: *A comparative analysis of current credit risk models*

---

## üë• Autores

**Pedro Schuves Marodin**  
**Enzo Holtzmann Gaio**

üìß Para suporte ou d√∫vidas, consulte os logs em `logs/` ou execute com `--mode analysis` para diagn√≥stico completo.

---

## üéâ Pr√≥ximos Passos

1. **Dados Reais**: Substitua dados simulados por APIs reais (ANP, ANEEL, IBGE)
2. **Deployment**: Configure ambiente de produ√ß√£o com Docker
3. **Dashboard**: Implemente dashboard executivo com m√©tricas de portf√≥lio
4. **APIs**: Crie endpoints REST para integra√ß√£o com sistemas existentes
5. **Alertas**: Sistema de notifica√ß√µes para drift e performance

---

**üöÄ Sistema pronto para uso! Execute `python main_pipeline.py --mode all` para come√ßar.**
